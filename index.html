<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Audio Chat</title>
    <script>
        let socket;
        let peerConnection;
        const config = { iceServers: [{ urls: "stun:stun.l.google.com:19302" }] };
        let localStream;

        // WebSocket 연결
        function connect(meetingId) {
            socket = new WebSocket(`ws://3.36.41.144:8000/ws/meeting/${meetingId}/`);

            socket.onopen = () => {
                console.log("WebSocket connection established.");
            };

            socket.onmessage = async (event) => {
                const data = JSON.parse(event.data);

                if (data.type === "offer") {
                    await handleOffer(data.offer);
                } else if (data.type === "answer") {
                    await handleAnswer(data.answer);
                } else if (data.type === "ice-candidate") {
                    await handleICECandidate(data.candidate);
                } else if (data.action === "receive_audio") {
                    // Base64 오디오 데이터 처리
                    console.log("Received audio data:", data.audio_data);
                    playReceivedAudio(data.audio_data);
                }
            };

            socket.onclose = () => {
                console.log("WebSocket connection closed.");
            };
        }

        // WebRTC 연결 초기화
        async function startCall() {
            localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            console.log(localStream);  // 로컬 스트림 확인
            peerConnection = new RTCPeerConnection(config);
        
            localStream.getTracks().forEach((track) => {
                console.log(track);  // 트랙이 제대로 연결되는지 확인
                peerConnection.addTrack(track, localStream);
            });
        
            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    socket.send(JSON.stringify({ type: "ice-candidate", candidate: event.candidate }));
                }
            };
        
            peerConnection.ontrack = (event) => {
                console.log("Received remote track:", event);  // 원격 트랙을 받았는지 확인
                const remoteAudio = document.createElement("audio");
                remoteAudio.srcObject = event.streams[0];  // 실제 오디오 스트림을 연결
                remoteAudio.autoplay = true;
                document.body.appendChild(remoteAudio);
            };
        
            const offer = await peerConnection.createOffer();
            await peerConnection.setLocalDescription(offer);
        
            socket.send(JSON.stringify({ type: "offer", offer }));
        }        

        async function handleOffer(offer) {
            if (!peerConnection) {
                await startCall();
            }

            await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
            const answer = await peerConnection.createAnswer();
            await peerConnection.setLocalDescription(answer);

            socket.send(JSON.stringify({ type: "answer", answer }));
        }

        async function handleAnswer(answer) {
            await peerConnection.setRemoteDescription(new RTCSessionDescription(answer));
        }

        async function handleICECandidate(candidate) {
            if (candidate) {
                await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
            }
        }

        // 오디오 데이터를 Base64로 변환하여 전송
        async function sendAudioData() {
            const audioData = await captureAudioData();  // 음성 데이터 캡처
            console.log("Sending audio data:", audioData);  // 송신할 오디오 데이터 로그

            socket.send(JSON.stringify({
                action: "send_audio",
                audio_data: audioData  // 서버로 음성 데이터 전송
            }));

            // 일정 시간 후에 계속해서 송신
            setTimeout(sendAudioData, 1000);  // 1초마다 반복 (실시간 송신)
        }

        // 오디오 데이터를 Base64로 인코딩하여 반환
        async function captureAudioData() {
            const audioBlob = await captureAudioStream();  // 오디오 스트림을 Blob 형태로 캡처
            const reader = new FileReader();

            return new Promise((resolve) => {
                reader.onloadend = () => {
                    resolve(reader.result);  // Base64 데이터 반환
                };
                reader.readAsDataURL(audioBlob);  // Blob 데이터를 Base64로 인코딩
            });
        }

        // 오디오 스트림 캡처 (가상의 코드)
        async function captureAudioStream() {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioChunks = [];
            const mediaRecorder = new MediaRecorder(stream);

            return new Promise((resolve) => {
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    resolve(audioBlob);  // Blob 객체 반환
                };
                mediaRecorder.start();
                
                setTimeout(() => {
                    mediaRecorder.stop();  // 3초 후 오디오 녹음 종료
                }, 3000);
            });
        }

        // 수신된 Base64 오디오 데이터를 처리하여 재생
        function playReceivedAudio(audioData) {
            const audioElement = new Audio();
            audioElement.src = audioData;  // Base64 오디오 데이터로 설정
            audioElement.play().catch(error => {
                console.error("Failed to play audio:", error);
            });
        }
    </script>
</head>
<body>
    <h1>Real-Time Audio Chat</h1>
    <input type="text" id="meetingId" placeholder="Meeting ID" />
    <button onclick="connect(document.getElementById('meetingId').value)">Connect</button>
    <br>
    <button onclick="startCall()">Start Call</button>
    <button onclick="sendAudioData()">Send Audio Data</button>  <!-- 실시간 오디오 송신 -->
</body>
</html>

